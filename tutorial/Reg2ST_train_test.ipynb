{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial of how to trian Reg2ST on your own computer.\n",
    "I beleive you have already create a  Reg2ST environment and downloaded all datasets needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step one: Import moudules needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herst import ViT_HER2ST, ViT_SKIN\n",
    "from model import Reg2ST\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from performance import get_R\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Two: Set some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_option():\n",
    "    # args = dict2namespace(config=update_config_from_file(args.cfg_file))\n",
    "    \n",
    "    parser = argparse.ArgumentParser(\n",
    "        'gene prediction', add_help=False)\n",
    "    parser.add_argument('--name', type=str, default='Reg2ST')\n",
    "    # preprocess\n",
    "    parser.add_argument('--dataset', type=str, default='her2st')\n",
    "\n",
    "    # model\n",
    "    parser.add_argument('--dim_in', type=int, default=1024)\n",
    "    parser.add_argument('--dim_hidden', type=int, default=256)\n",
    "    parser.add_argument('--dim_out', type=int, default=785)\n",
    "    parser.add_argument('--dropout', type=float, default=0.2)\n",
    "    parser.add_argument('--wikg_top', type=int, default=6)\n",
    "    parser.add_argument('--decoder_layer', type=int, default=6)\n",
    "    parser.add_argument('--decoder_head', type=int, default=8)\n",
    "\n",
    "    parser.add_argument('--mask_rate', type=float, default=0.75)\n",
    "    parser.add_argument('--w_con', type=float, default=0.5)    \n",
    "    parser.add_argument('--w_zinb', type=float, default=0.25)\n",
    "\n",
    "    # trains\n",
    "    parser.add_argument('--epochs', type=int, default=400)\n",
    "    # parser.add_argument(\"--fold\", type=int, default=0, help=\"fold number\")\n",
    "    parser.add_argument('--device_id', type=int, default=0)\n",
    "    args_cmd, _ = parser.parse_known_args()\n",
    "    # print(type(vars(args_cmd)))\n",
    "    return args_cmd\n",
    "\n",
    "args = parser_option()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Three: Train the model.\n",
    "All code is implemetend through Pytorch-Lightning. Here are some detailed explaination about classes used in code.\n",
    "\n",
    "The `Trainer` is the core class in PyTorch Lightning that simplifies the training process. It encapsulates all logic related to training, validation, testing, and prediction, allowing us to focus solely on model implementation. You can control the training flow flexibly by setting parameters such as max_epochs, gpus, and callbacks. \n",
    "\n",
    "`CSVLogger` is a logging utility that records training and validation metrics (such as loss and accuracy) for each epoch into a .csv file. This file can be used for further analysis, such as plotting performance curves or comparing different experiments. \n",
    "\n",
    "`ModelCheckpoint` is a callback function used to automatically save the model during training. You can configure it to save models based on specific metrics (e.g., validation loss or accuracy) and choose whether to save only the best model or one for each epoch. It is very useful for model recovery, hyperparameter tuning, and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    i = args.fold\n",
    "\n",
    "    save_dir = f\"{args.dataset}_model/\"\n",
    "    \n",
    "    # trained models are saved in save_dir and named as fold{fold}_model.ckpt.\n",
    "    val_checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=save_dir,\n",
    "    filename=f\"fold{i}_model\",\n",
    "    save_last=True,\n",
    "    save_top_k=0,\n",
    "    save_on_train_epoch_end=True\n",
    "    )\n",
    "    \n",
    "    # Detailed training and validation metrics are recorded automatically in {datasets}_fold{fold}.\n",
    "    logger_name = f'{args.dataset}_fold{i}/'\n",
    "    csv_logger = CSVLogger(logger_name, name=f\"fold{i}\")\n",
    "    \n",
    "    # Different output dimensions are setted according to gene numbers of HER2+ and cSCC.\n",
    "    if args.dataset == \"her2st\":\n",
    "        train_data = ViT_HER2ST(train=True, flatten=False,ori=True, adj=False, fold=i)\n",
    "        val_data = ViT_HER2ST(train=False, flatten=False,ori=True, adj=False, fold=i)\n",
    "    else:\n",
    "        args.dim_out = 171\n",
    "        train_data = ViT_SKIN(train=True, flatten=False, ori=True, adj=False, fold=i)\n",
    "        val_data = ViT_SKIN(train=False, flatten=False, ori=True, adj=False, fold=i)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=1, shuffle=False, pin_memory=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "    model = Reg2ST(args=args)\n",
    "    trainer = pl.Trainer(logger=csv_logger, precision=32, max_epochs=args.epochs, \n",
    "                         accelerator='gpu', devices=[args.device_id], \n",
    "                         callbacks=[val_checkpoint_callback], \n",
    "                         log_every_n_steps=5)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Four: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(args):\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    if args.dataset == \"her2st\":\n",
    "        val_data = ViT_HER2ST(train=False, flatten=False,ori=True, adj=False, fold=args.fold)\n",
    "        args.dimout = 785\n",
    "    else:\n",
    "        val_data = ViT_SKIN(train=False, flatten=False, ori=True, adj=False, fold=args.fold)\n",
    "        args.dim_out = 171\n",
    "    val_loader = DataLoader(val_data, batch_size=1, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    # Download checkpoints and put them into current directory.\n",
    "    ckpt_dir = f\"{args.dataset}_model/fold{args.fold}_model.ckpt\"\n",
    "    print(f\"Loading checkpoints from {ckpt_dir}\")\n",
    "    model = Reg2ST(args)\n",
    "    trainer = pl.Trainer(precision=32, max_epochs=args.epochs, \n",
    "                         accelerator='gpu', devices=[args.device_id])\n",
    "    trainer.test(model, val_loader, ckpt_path=ckpt_dir)\n",
    "    \n",
    "predict()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
